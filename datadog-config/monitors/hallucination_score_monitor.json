{
    "name": "[Quality Alert] LLM Incident Commander - High hallucination score",
    "type": "metric alert",
    "query": "avg(last_10m):avg:llm.hallucination.score{service:llm-incident-commander} > 0.7",
    "message": "## ⚠️ LLM Quality Degradation Detected\n\nThe LLM is producing responses with high uncertainty indicators.\n\n**Current Metrics:**\n- Hallucination score: {{value}} (threshold: 0.7)\n- Service: {{service.name}}\n\n**What This Means:**\nThe LLM responses contain phrases indicating uncertainty such as:\n- \"I think\", \"maybe\", \"might be wrong\"\n- \"not sure\", \"possibly\", \"could be\"\n\nThis may indicate:\n- Model degradation\n- Input quality issues  \n- Prompt engineering problems\n\n**Context:**\n- [View Recent Requests](https://app.datadoghq.com/apm/services/llm-incident-commander)\n- [View Logs with High Scores](https://app.datadoghq.com/logs?query=hallucination_score:>0.7)\n\n**Runbook:**\n1. Review sample responses with high scores\n2. Analyze prompt patterns\n3. Check if specific question types trigger this\n4. Consider prompt engineering improvements\n5. Evaluate if model fine-tuning is needed\n\n**Next Steps:**\n- Create case for AI engineering review\n- Collect examples for analysis\n- Consider adjusting temperature or generation parameters\n\n@case-llm-quality-team",
    "tags": [
        "service:llm-incident-commander",
        "severity:medium",
        "category:quality"
    ],
    "options": {
        "thresholds": {
            "critical": 0.7,
            "warning": 0.5
        },
        "notify_no_data": false,
        "notify_audit": false,
        "require_full_window": true,
        "new_group_delay": 60,
        "include_tags": true,
        "renotify_interval": 120,
        "timeout_h": 0,
        "evaluation_delay": 60
    },
    "priority": 4,
    "restricted_roles": null
}